{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import time\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset \n",
    "\n",
    "#### Download only the following zip file: VeReMi_54000_57600_2022-9-11_19.12.56.zip\n",
    "\n",
    "#### https://mega.nz/folder/z0pnGA4a#WFEUISyS5_maabhcEI7HQA/folder/a1QxhaqC\n",
    "\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipfile(filename):\n",
    "    with zipfile.ZipFile(filename,\"r\") as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the files\n",
    "# We assume the dataset file and the current python file are in the same folder. \n",
    "# Otherwise, the path of the dataset file should be revised in the following line.\n",
    "\n",
    "# unzipfile(\"VeReMi_50400_54000_2022-9-11_19.12.56.zip\")\n",
    "unzipfile(\"VeReMi_54000_57600_2022-9-11_19.12.56.zip\")\n",
    "# unzipfile(\"VeReMi_57600_61200_2022-9-11_19.12.56.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the dataset\n",
    "path_1 = 'VeReMi_54000_57600_2022-9-11_19_12_56'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the json files in each folder\n",
    "list_of_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(path_1):\n",
    "    for file in files:\n",
    "        list_of_files.append(os.path.join(root,file))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Each folder has one json file for the ground truth, we want to skip them\n",
    "\n",
    "list_of_files.remove('VeReMi_54000_57600_2022-9-11_19_12_56\\\\traceGroundTruthJSON-15.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of json\n",
    "nb_each_json = []\n",
    "\n",
    "for index in range(len(list_of_files)):\n",
    "    nb_each_json.append(sum(1 for line in open(list_of_files[index])))\n",
    "\n",
    "len(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for index in range(len(list_of_files)):\n",
    "    with open(list_of_files[index]) as f:\n",
    "        # Read all the data in the files\n",
    "        df = pd.DataFrame(json.loads(line) for line in f)\n",
    "        # Read the following features from the name of json file (by splitting the file name)\n",
    "        # labelRec: the label (0 normal, 13 (for this type of attack) attacker)\n",
    "        # receiver: the receiver ID\n",
    "        # moduleid: OMNeT++ module number, we don't need it now\n",
    "        df['labelRec'] = list_of_files[index].rsplit('\\\\')[1].rsplit('-')[3].rsplit('A')[1]\n",
    "        df['receiver'] = list_of_files[index].rsplit('\\\\')[1].rsplit('-')[1]\n",
    "        # df['moduleid'] = list_of_files[index].rsplit('\\\\')[1].rsplit('-')[4]\n",
    "        data = pd.concat([data,df])\n",
    "    print(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the BSM where type = 3 (type = 2 GPS is just the sent messages, we will use the received messages, i.e. BSM)\n",
    "\n",
    "bsm = data[data.type==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos, Spd, Acl, Hed, and their noise features have three axis: x,y,z. \n",
    "# This function separates their x and y axis (z is always 0 for all, so we did not consider them.)\n",
    "def clean_dataset(l, droped_features, data):\n",
    "    for t in l:\n",
    "        data[t + '_x'] = None\n",
    "        data[t + '_y'] = None\n",
    "\n",
    "    for j in l:\n",
    "        data[j + '_x'] = data[j].apply(lambda row: row[0]) \n",
    "        data[j + '_y'] = data[j].apply(lambda row: row[1])\n",
    "    data = data.drop(columns=l,axis=1)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.drop(columns= droped_features,inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features who needs to be separated for the different axis\n",
    "l = ['pos', 'pos_noise', 'spd', 'spd_noise', 'acl', 'acl_noise', 'hed', 'hed_noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using clean_dataset function, separate the features in l to their x and y axis\n",
    "droped_features = []\n",
    "bsm = clean_dataset(l, droped_features, bsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm['receiver'] = bsm['receiver'].astype(\"float64\")\n",
    "# bsm['sender'] = bsm['sender'].astype(\"float64\")\n",
    "bsm['labelRec'] = bsm['labelRec'].astype(\"int64\")\n",
    "\n",
    "bsm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receiver - Sender matching\n",
    "\n",
    "labelization = bsm[['receiver','labelRec']]\n",
    "labelization.drop_duplicates(inplace=True)\n",
    "bsm = bsm.drop(columns=['receiver','labelRec'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsm = pd.merge(bsm, labelization ,left_on='sender',right_on='receiver',how='left')\n",
    "bsm.rename(columns={'labelRec':'label'},inplace=True)\n",
    "bsm = bsm.drop(columns=['receiver'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm = bsm.dropna()\n",
    "# or:  bsm.dropna(inplace = True)\n",
    "bsm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm['label'] = bsm['label'].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of lines in the dataset\n",
    "len(bsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of normal vehicles (0) and number of attackers (13) in the dataset\n",
    "bsm.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_attack(method,veremi):\n",
    "       \n",
    "    # Our labels are 0 or 13; we need 0-1 for classification algorithms. Convert 13 to 1\n",
    "    veremi['label'] = veremi['label'].replace(13,1)\n",
    "    \n",
    "    # Create feature set X and label set y \n",
    "    y = veremi['label']\n",
    "    X = veremi.drop(columns=['label','type', 'rcvTime', 'sendTime', 'sender', 'senderPseudo', 'messageID'], axis=1)\n",
    "    \n",
    "    # Data split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0, stratify=y)\n",
    "    \n",
    "             \n",
    "    if method=='RF':\n",
    "        # Random Forest\n",
    "        rf = RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=0)\n",
    "\n",
    "        start = time.time()\n",
    "        rf.fit(X_train, y_train)\n",
    "        timefit = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        y_pred = rf.predict(X_test)\n",
    "        timepred = time.time() - start\n",
    "        \n",
    "    \n",
    "    elif method=='Xgboost':\n",
    "        # XGBoost\n",
    "        xgb = XGBClassifier(random_state=0)\n",
    "\n",
    "        start = time.time()\n",
    "        xgb.fit(X_train,y_train)\n",
    "        timefit = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        y_pred = xgb.predict(X_test)\n",
    "        timepred = time.time() - start\n",
    "\n",
    "           \n",
    "   \n",
    "       \n",
    "    report = classification_report(y_test,y_pred,output_dict=True)\n",
    "\n",
    "    return(report['accuracy'], report['weighted avg']['precision'], report['weighted avg']['recall'], \n",
    "          report['weighted avg']['f1-score'], timefit, timepred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs and Stockage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classifying = pd.DataFrame(index=['Xgboost','RF'],\n",
    "                       columns=['Acc','Pre','Rec','F1s','TimeFit','TimePred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classifying.xs('Xgboost')[:] = classification_attack('Xgboost',bsm)\n",
    "print(results_classifying)\n",
    "results_classifying.xs('RF')[:] = classification_attack('RF',bsm)\n",
    "print(results_classifying)\n",
    "\n",
    "results_classifying.to_excel('results_classifying.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage of the data\n",
    "bsm.to_csv('bsm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the saved data \n",
    "bsm_copy = pd.read_csv('bsm.csv')\n",
    "#bsm_copy.drop(columns='Unnamed: 0', inplace=True)\n",
    "bsm_copy.head()\n",
    "\n",
    "## Read the saved results\n",
    "#results_classifying_copy = pd.read_excel('results_classifying.xlsx')\n",
    "#results_classifying_copy.rename(columns={'Unnamed: 0': 'method'}, inplace=True)\n",
    "#results_classifying_copy.set_index('method', inplace=True)\n",
    "#print(results_classifying_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import homogeneity_score, completeness_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_attack(method,veremi):\n",
    "       \n",
    "    # Our labels are 0 or 13; we need 0-1 for classification algorithms. Convert 13 to 1\n",
    "    veremi['label'] = veremi['label'].replace(13,1)\n",
    "    \n",
    "    # Create feature set X and label set y \n",
    "    y = veremi['label']\n",
    "    X = veremi.drop(columns=['label','type', 'rcvTime', 'sendTime', 'sender', 'senderPseudo', 'messageID'], axis=1)\n",
    "    \n",
    "    # Data split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0, stratify=y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_train = scaler.fit_transform(X_train)\n",
    "    scaled_X_test = scaler.fit_transform(X_test)\n",
    "             \n",
    "    if method=='kMeans':\n",
    "        # k-Means\n",
    "        kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "        \n",
    "        start = time.time()\n",
    "        kmeans.fit(scaled_X_train)\n",
    "        timefit = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        y_pred = kmeans.predict(scaled_X_test)\n",
    "        timepred = time.time() - start\n",
    "    \n",
    "    elif method=='GMM':\n",
    "        # Gaussian Mixture Model\n",
    "        gmm = GaussianMixture(n_components=2, random_state=0)\n",
    "\n",
    "        start = time.time()\n",
    "        gmm.fit(scaled_X_train)\n",
    "        timefit = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        y_pred = gmm.predict(scaled_X_test)\n",
    "        timepred = time.time() - start\n",
    "\n",
    "           \n",
    "              \n",
    "   \n",
    "       \n",
    "    report = classification_report(y_test,y_pred,output_dict=True)\n",
    "\n",
    "    return(report['accuracy'], report['weighted avg']['precision'], report['weighted avg']['recall'], \n",
    "          report['weighted avg']['f1-score'], timefit, timepred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs and Stockage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cluster = pd.DataFrame(index=['kMeans','GMM'],\n",
    "                       columns=['Acc','Pre','Rec','F1s','TimeFit','TimePred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cluster.xs('kMeans')[:] = clustering_attack('kMeans',bsm)\n",
    "print(results_cluster)\n",
    "results_cluster.xs('GMM')[:] = clustering_attack('GMM',bsm)\n",
    "print(results_cluster)\n",
    "\n",
    "results_cluster.to_excel('results_cluster.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm['label'] = bsm['label'].replace(13,1)\n",
    "y = bsm['label']\n",
    "X = bsm.drop(columns=['label','type', 'rcvTime', 'sendTime', 'sender', 'senderPseudo', 'messageID'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6)) \n",
    "sns.heatmap(cm, annot=True, cbar=False, cmap='Blues', fmt='.0f')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area Under the Curve) and Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]\n",
    "\n",
    "xgb.fit(X_train, y_train, eval_set=eval_set, eval_metric=eval_metric, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xgb.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['auc'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['auc'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('AUC')\n",
    "pyplot.title('XGBoost AUC')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.title('XGBoost Error')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
